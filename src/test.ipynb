{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import from_unixtime, col,to_date, date_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/13 10:04:58 WARN Utils: Your hostname, ali-ThinkBook-14-G2-ITL resolves to a loopback address: 127.0.1.1; using 172.16.8.114 instead (on interface wlp0s20f3)\n",
      "25/03/13 10:04:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/13 10:04:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('movie').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = spark.read.csv(\"file:///home/ali/Desktop/Movie Recommendation System/data/ml-100k/u.data\", \n",
    "                    sep=\"\\t\", \n",
    "                    schema=\"userId INT, movieId INT, rating FLOAT, timestamp LONG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|   196|    242|   3.0|881250949|\n",
      "|   186|    302|   3.0|891717742|\n",
      "|    22|    377|   1.0|878887116|\n",
      "|   244|     51|   2.0|880606923|\n",
      "|   166|    346|   1.0|886397596|\n",
      "|   298|    474|   4.0|884182806|\n",
      "|   115|    265|   2.0|881171488|\n",
      "|   253|    465|   5.0|891628467|\n",
      "|   305|    451|   3.0|886324817|\n",
      "|     6|     86|   3.0|883603013|\n",
      "|    62|    257|   2.0|879372434|\n",
      "|   286|   1014|   5.0|879781125|\n",
      "|   200|    222|   5.0|876042340|\n",
      "|   210|     40|   3.0|891035994|\n",
      "|   224|     29|   3.0|888104457|\n",
      "|   303|    785|   3.0|879485318|\n",
      "|   122|    387|   5.0|879270459|\n",
      "|   194|    274|   2.0|879539794|\n",
      "|   291|   1042|   4.0|874834944|\n",
      "|   234|   1184|   2.0|892079237|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre = spark.read.csv(\"file:///home/ali/Desktop/Movie Recommendation System/data/ml-100k/u.genre\", \n",
    "                           sep=\"|\", \n",
    "                           schema=\"genre STRING, id INT\")\n",
    "\n",
    "df_info = spark.read.csv(\"file:///home/ali/Desktop/Movie Recommendation System/data/ml-100k/u.info\", \n",
    "                          sep=\" \", \n",
    "                          schema=\"value INT, description STRING\")\n",
    "\n",
    "df_item = spark.read.csv(\"file:///home/ali/Desktop/Movie Recommendation System/data/ml-100k/u.item\", \n",
    "                          sep=\"|\", \n",
    "                          schema=\"movieId INT, movieTitle STRING, releaseDate STRING, videoReleaseDate STRING, imdbUrl STRING, unknown INT, action INT, adventure INT, animation INT, childrens INT, comedy INT, crime INT, documentary INT, drama INT, fantasy INT, filmNoir INT, horror INT, musical INT, mystery INT, romance INT, sciFi INT, thriller INT, war INT, western INT\")\n",
    "\n",
    "df_occupation = spark.read.csv(\"file:///home/ali/Desktop/Movie Recommendation System/data/ml-100k/u.occupation\", \n",
    "                                 schema=\"occupation STRING\")\n",
    "\n",
    "df_user = spark.read.csv(\"file:///home/ali/Desktop/Movie Recommendation System/data/ml-100k/u.user\", \n",
    "                          sep=\"|\", \n",
    "                          schema=\"userId INT, age INT, gender STRING, occupation STRING, zipCode STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|      genre| id|\n",
      "+-----------+---+\n",
      "|    unknown|  0|\n",
      "|     Action|  1|\n",
      "|  Adventure|  2|\n",
      "|  Animation|  3|\n",
      "| Children's|  4|\n",
      "|     Comedy|  5|\n",
      "|      Crime|  6|\n",
      "|Documentary|  7|\n",
      "|      Drama|  8|\n",
      "|    Fantasy|  9|\n",
      "|  Film-Noir| 10|\n",
      "|     Horror| 11|\n",
      "|    Musical| 12|\n",
      "|    Mystery| 13|\n",
      "|    Romance| 14|\n",
      "|     Sci-Fi| 15|\n",
      "|   Thriller| 16|\n",
      "|        War| 17|\n",
      "|    Western| 18|\n",
      "+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_genre.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------------+-----------+----------------+-------------------------------------------------------------------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\n",
      "|movieId|movieTitle                                          |releaseDate|videoReleaseDate|imdbUrl                                                            |unknown|action|adventure|animation|childrens|comedy|crime|documentary|drama|fantasy|filmNoir|horror|musical|mystery|romance|sciFi|thriller|war|western|\n",
      "+-------+----------------------------------------------------+-----------+----------------+-------------------------------------------------------------------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\n",
      "|1      |Toy Story (1995)                                    |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)              |0      |0     |0        |1        |1        |1     |0    |0          |0    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|2      |GoldenEye (1995)                                    |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?GoldenEye%20(1995)                |0      |1     |1        |0        |0        |0     |0    |0          |0    |0      |0       |0     |0      |0      |0      |0    |1       |0  |0      |\n",
      "|3      |Four Rooms (1995)                                   |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)             |0      |0     |0        |0        |0        |0     |0    |0          |0    |0      |0       |0     |0      |0      |0      |0    |1       |0  |0      |\n",
      "|4      |Get Shorty (1995)                                   |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)             |0      |1     |0        |0        |0        |1     |0    |0          |1    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|5      |Copycat (1995)                                      |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Copycat%20(1995)                  |0      |0     |0        |0        |0        |0     |1    |0          |1    |0      |0       |0     |0      |0      |0      |0    |1       |0  |0      |\n",
      "|6      |Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)|01-Jan-1995|NULL            |http://us.imdb.com/Title?Yao+a+yao+yao+dao+waipo+qiao+(1995)       |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|7      |Twelve Monkeys (1995)                               |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Twelve%20Monkeys%20(1995)         |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |0      |1    |0       |0  |0      |\n",
      "|8      |Babe (1995)                                         |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Babe%20(1995)                     |0      |0     |0        |0        |1        |1     |0    |0          |1    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|9      |Dead Man Walking (1995)                             |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Dead%20Man%20Walking%20(1995)     |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|10     |Richard III (1995)                                  |22-Jan-1996|NULL            |http://us.imdb.com/M/title-exact?Richard%20III%20(1995)            |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |0      |0    |0       |1  |0      |\n",
      "|11     |Seven (Se7en) (1995)                                |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Se7en%20(1995)                    |0      |0     |0        |0        |0        |0     |1    |0          |0    |0      |0       |0     |0      |0      |0      |0    |1       |0  |0      |\n",
      "|12     |Usual Suspects, The (1995)                          |14-Aug-1995|NULL            |http://us.imdb.com/M/title-exact?Usual%20Suspects,%20The%20(1995)  |0      |0     |0        |0        |0        |0     |1    |0          |0    |0      |0       |0     |0      |0      |0      |0    |1       |0  |0      |\n",
      "|13     |Mighty Aphrodite (1995)                             |30-Oct-1995|NULL            |http://us.imdb.com/M/title-exact?Mighty%20Aphrodite%20(1995)       |0      |0     |0        |0        |0        |1     |0    |0          |0    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|14     |Postino, Il (1994)                                  |01-Jan-1994|NULL            |http://us.imdb.com/M/title-exact?Postino,%20Il%20(1994)            |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |1      |0    |0       |0  |0      |\n",
      "|15     |Mr. Holland's Opus (1995)                           |29-Jan-1996|NULL            |http://us.imdb.com/M/title-exact?Mr.%20Holland's%20Opus%20(1995)   |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|16     |French Twist (Gazon maudit) (1995)                  |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Gazon%20maudit%20(1995)           |0      |0     |0        |0        |0        |1     |0    |0          |0    |0      |0       |0     |0      |0      |1      |0    |0       |0  |0      |\n",
      "|17     |From Dusk Till Dawn (1996)                          |05-Feb-1996|NULL            |http://us.imdb.com/M/title-exact?From%20Dusk%20Till%20Dawn%20(1996)|0      |1     |0        |0        |0        |1     |1    |0          |0    |0      |0       |1     |0      |0      |0      |0    |1       |0  |0      |\n",
      "|18     |White Balloon, The (1995)                           |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Badkonake%20Sefid%20(1995)        |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|19     |Antonia's Line (1995)                               |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Antonia%20(1995)                  |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |0      |0    |0       |0  |0      |\n",
      "|20     |Angels and Insects (1995)                           |01-Jan-1995|NULL            |http://us.imdb.com/M/title-exact?Angels%20and%20Insects%20(1995)   |0      |0     |0        |0        |0        |0     |0    |0          |1    |0      |0       |0     |0      |0      |1      |0    |0       |0  |0      |\n",
      "+-------+----------------------------------------------------+-----------+----------------+-------------------------------------------------------------------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_item.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime, col\n",
    "\n",
    "df=df_data.join(df_user,'userId',how='inner').join(df_item,'movieId','inner').withColumn('datetime',from_unixtime(col(\"timestamp\"))).drop('timestamp').withColumn('time',date_format(col(\"datetime\"),\"HH:mm:ss\")).withColumn('date',to_date(col(\"datetime\"))).drop('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/13 10:05:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---+------+-------------+-------+--------------------+-----------+----------------+--------------------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+--------+----------+\n",
      "|movieId|userId|rating|age|gender|   occupation|zipCode|          movieTitle|releaseDate|videoReleaseDate|             imdbUrl|unknown|action|adventure|animation|childrens|comedy|crime|documentary|drama|fantasy|filmNoir|horror|musical|mystery|romance|sciFi|thriller|war|western|    time|      date|\n",
      "+-------+------+------+---+------+-------------+-------+--------------------+-----------+----------------+--------------------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+--------+----------+\n",
      "|    242|   196|   3.0| 49|     M|       writer|  55105|        Kolya (1996)|24-Jan-1997|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     1|    0|          0|    0|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|15:55:49|1997-12-04|\n",
      "|    302|   186|   3.0| 39|     F|    executive|  00000|L.A. Confidential...|01-Jan-1997|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     0|    1|          0|    0|      0|       1|     0|      0|      1|      0|    0|       1|  0|      0|19:22:22|1998-04-04|\n",
      "|    377|    22|   1.0| 25|     M|       writer|  40206| Heavyweights (1994)|01-Jan-1994|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        1|     1|    0|          0|    0|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|07:18:36|1997-11-07|\n",
      "|     51|   244|   2.0| 28|     M|   technician|  80525|Legends of the Fa...|01-Jan-1994|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     0|    0|          0|    1|      0|       0|     0|      0|      0|      1|    0|       0|  1|      1|05:02:03|1997-11-27|\n",
      "|    346|   166|   1.0| 47|     M|     educator|  55113| Jackie Brown (1997)|01-Jan-1997|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     0|    1|          0|    1|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|05:33:16|1998-02-02|\n",
      "|    474|   298|   4.0| 44|     M|    executive|  01581|Dr. Strangelove o...|01-Jan-1963|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     0|    0|          0|    0|      0|       0|     0|      0|      0|      0|    1|       0|  1|      0|14:20:06|1998-01-07|\n",
      "|    265|   115|   2.0| 31|     M|     engineer|  17110|Hunt for Red Octo...|01-Jan-1990|            NULL|http://us.imdb.co...|      0|     1|        0|        0|        0|     0|    0|          0|    0|      0|       0|     0|      0|      0|      0|    0|       1|  0|      0|17:51:28|1997-12-03|\n",
      "|    465|   253|   5.0| 26|     F|    librarian|  22903|Jungle Book, The ...|01-Jan-1994|            NULL|http://us.imdb.co...|      0|     0|        1|        0|        1|     0|    0|          0|    0|      0|       0|     0|      0|      0|      1|    0|       0|  0|      0|18:34:27|1998-04-03|\n",
      "|    451|   305|   3.0| 23|     M|   programmer|  94086|       Grease (1978)|01-Jan-1978|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     1|    0|          0|    0|      0|       0|     0|      1|      0|      1|    0|       0|  0|      0|09:20:17|1998-02-01|\n",
      "|     86|     6|   3.0| 42|     M|    executive|  98101|Remains of the Da...|01-Jan-1993|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     0|    0|          0|    1|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|21:16:53|1997-12-31|\n",
      "|    257|    62|   2.0| 27|     F|administrator|  97214| Men in Black (1997)|04-Jul-1997|            NULL|http://us.imdb.co...|      0|     1|        1|        0|        0|     1|    0|          0|    0|      0|       0|     0|      0|      0|      0|    1|       0|  0|      0|22:07:14|1997-11-12|\n",
      "|   1014|   286|   5.0| 27|     M|      student|  15217|Romy and Michele'...|25-Apr-1997|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     1|    0|          0|    0|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|15:38:45|1997-11-17|\n",
      "|    222|   200|   5.0| 40|     M|   programmer|  93402|Star Trek: First ...|22-Nov-1996|            NULL|http://us.imdb.co...|      0|     1|        1|        0|        0|     0|    0|          0|    0|      0|       0|     0|      0|      0|      0|    1|       0|  0|      0|09:05:40|1997-10-05|\n",
      "|     40|   210|   3.0| 39|     M|     engineer|  03060|To Wong Foo, Than...|01-Jan-1995|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     1|    0|          0|    0|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|21:59:54|1998-03-27|\n",
      "|     29|   224|   3.0| 31|     F|     educator|  43512|Batman Forever (1...|01-Jan-1995|            NULL|http://us.imdb.co...|      0|     1|        1|        0|        0|     1|    1|          0|    0|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|23:40:57|1998-02-21|\n",
      "|    785|   303|   3.0| 19|     M|      student|  14853|     Only You (1994)|01-Jan-1994|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     1|    0|          0|    0|      0|       0|     0|      0|      0|      1|    0|       0|  0|      0|05:28:38|1997-11-14|\n",
      "|    387|   122|   5.0| 32|     F|       writer|  22206|Age of Innocence,...|01-Jan-1993|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     0|    0|          0|    1|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|17:47:39|1997-11-11|\n",
      "|    274|   194|   2.0| 38|     M|administrator|  02154|      Sabrina (1995)|01-Jan-1995|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     1|    0|          0|    0|      0|       0|     0|      0|      0|      1|    0|       0|  0|      0|20:36:34|1997-11-14|\n",
      "|   1042|   291|   4.0| 19|     M|      student|  44106|   Just Cause (1995)|01-Jan-1995|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     0|    0|          0|    0|      0|       0|     0|      0|      1|      0|    0|       1|  0|      0|09:42:24|1997-09-21|\n",
      "|   1184|   234|   2.0| 60|     M|      retired|  94702|Endless Summer 2,...|01-Jan-1994|            NULL|http://us.imdb.co...|      0|     0|        0|        0|        0|     0|    0|          1|    0|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|23:47:17|1998-04-08|\n",
      "+-------+------+------+---+------+-------------+-------+--------------------+-----------+----------------+--------------------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data=df_data.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|   196|    242|   3.0|\n",
      "|   186|    302|   3.0|\n",
      "|    22|    377|   1.0|\n",
      "|   244|     51|   2.0|\n",
      "|   166|    346|   1.0|\n",
      "|   298|    474|   4.0|\n",
      "|   115|    265|   2.0|\n",
      "|   253|    465|   5.0|\n",
      "|   305|    451|   3.0|\n",
      "|     6|     86|   3.0|\n",
      "|    62|    257|   2.0|\n",
      "|   286|   1014|   5.0|\n",
      "|   200|    222|   5.0|\n",
      "|   210|     40|   3.0|\n",
      "|   224|     29|   3.0|\n",
      "|   303|    785|   3.0|\n",
      "|   122|    387|   5.0|\n",
      "|   194|    274|   2.0|\n",
      "|   291|   1042|   4.0|\n",
      "|   234|   1184|   2.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: float]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|   196|    242|   3.0|\n",
      "|   186|    302|   3.0|\n",
      "|    22|    377|   1.0|\n",
      "|   244|     51|   2.0|\n",
      "|   166|    346|   1.0|\n",
      "|   298|    474|   4.0|\n",
      "|   115|    265|   2.0|\n",
      "|   253|    465|   5.0|\n",
      "|   305|    451|   3.0|\n",
      "|     6|     86|   3.0|\n",
      "|    62|    257|   2.0|\n",
      "|   286|   1014|   5.0|\n",
      "|   200|    222|   5.0|\n",
      "|   210|     40|   3.0|\n",
      "|   224|     29|   3.0|\n",
      "|   303|    785|   3.0|\n",
      "|   122|    387|   5.0|\n",
      "|   194|    274|   2.0|\n",
      "|   291|   1042|   4.0|\n",
      "|   234|   1184|   2.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_tarin,df_data_test=df_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79888"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_tarin.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20112"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "als=ALS(maxIter=10,rank=4,regParam=0.1,userCol='userId',itemCol='movieId',ratingCol='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=als.fit(df_data_tarin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.transform(df_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|      1|   5.0| 3.8165877|\n",
      "|     1|      7|   4.0|   4.03037|\n",
      "|     1|     10|   3.0| 4.0765753|\n",
      "|     1|     16|   5.0| 3.5653815|\n",
      "|     1|     17|   3.0| 3.0659015|\n",
      "|     1|     34|   2.0| 1.3376474|\n",
      "|     1|     39|   4.0| 3.3385286|\n",
      "|     1|     41|   2.0| 2.5630927|\n",
      "|     1|     45|   5.0|  4.247238|\n",
      "|     1|     51|   4.0| 3.1219783|\n",
      "|     1|     56|   4.0|  4.376049|\n",
      "|     1|     57|   5.0| 3.8636377|\n",
      "|     1|     59|   5.0|  4.281887|\n",
      "|     1|     66|   4.0| 2.8900228|\n",
      "|     1|     68|   4.0| 3.3818574|\n",
      "|     1|     75|   4.0| 3.8104255|\n",
      "|     1|     76|   4.0| 3.4756641|\n",
      "|     1|     81|   5.0|  3.902081|\n",
      "|     1|     82|   5.0| 3.3808446|\n",
      "|     1|     87|   5.0|  3.840701|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=RegressionEvaluator(metricName='rmse',predictionCol='prediction',labelCol='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=predictions.filter(col('prediction')!='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse=evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222796504357282\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-12 22:15:29.411363\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-12\n"
     ]
    }
   ],
   "source": [
    "print(datetime.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "als=ALS(userCol='userId',itemCol='movieId',ratingCol='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramgrid=ParamGridBuilder().addGrid(als.regParam,[0.3,0.01,0.15]).addGrid(als.rank,range(2,8)).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=RegressionEvaluator(metricName='rmse',predictionCol='prediction',labelCol='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval=CrossValidator(estimator=als,estimatorParamMaps=paramgrid,evaluator=evaluator,numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossmodel=crossval.fit(df_data_tarin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=crossmodel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=best_model.transform(df_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|      1|   5.0| 3.5930758|\n",
      "|     1|      7|   4.0| 3.6004226|\n",
      "|     1|     10|   3.0| 3.6383452|\n",
      "|     1|     16|   5.0|  3.093947|\n",
      "|     1|     17|   3.0| 2.8954697|\n",
      "|     1|     34|   2.0|  2.085077|\n",
      "|     1|     39|   4.0| 3.0860734|\n",
      "|     1|     41|   2.0| 2.7528162|\n",
      "|     1|     45|   5.0|  3.847292|\n",
      "|     1|     51|   4.0| 3.1340594|\n",
      "|     1|     56|   4.0| 3.8344424|\n",
      "|     1|     57|   5.0| 3.6827676|\n",
      "|     1|     59|   5.0| 3.8919723|\n",
      "|     1|     66|   4.0|   3.10332|\n",
      "|     1|     68|   4.0| 3.1840281|\n",
      "|     1|     75|   4.0| 2.9401517|\n",
      "|     1|     76|   4.0| 3.2980647|\n",
      "|     1|     81|   5.0| 3.4151716|\n",
      "|     1|     82|   5.0|  3.434549|\n",
      "|     1|     87|   5.0| 3.6772847|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse=evaluator.evaluate(predictions.filter(col('prediction')!='nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9753243913726617\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|      1|   5.0| 3.5930758|\n",
      "|     1|      7|   4.0| 3.6004226|\n",
      "|     1|     10|   3.0| 3.6383452|\n",
      "|     1|     16|   5.0|  3.093947|\n",
      "|     1|     17|   3.0| 2.8954697|\n",
      "|     1|     34|   2.0|  2.085077|\n",
      "|     1|     39|   4.0| 3.0860734|\n",
      "|     1|     41|   2.0| 2.7528162|\n",
      "|     1|     45|   5.0|  3.847292|\n",
      "|     1|     51|   4.0| 3.1340594|\n",
      "|     1|     56|   4.0| 3.8344424|\n",
      "|     1|     57|   5.0| 3.6827676|\n",
      "|     1|     59|   5.0| 3.8919723|\n",
      "|     1|     66|   4.0|   3.10332|\n",
      "|     1|     68|   4.0| 3.1840281|\n",
      "|     1|     75|   4.0| 2.9401517|\n",
      "|     1|     76|   4.0| 3.2980647|\n",
      "|     1|     81|   5.0| 3.4151716|\n",
      "|     1|     82|   5.0|  3.434549|\n",
      "|     1|     87|   5.0| 3.6772847|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df_data_tarin,df_data_test=df_data.randomSplit([0.8,0.2])\n",
    "als=ALS(userCol='userId',itemCol='movieId',ratingCol='rating')\n",
    "paramgrid=ParamGridBuilder().addGrid(als.regParam,[0.3,0.01,0.15]).addGrid(als.rank,range(2,8)).build()\n",
    "evaluator=RegressionEvaluator(metricName='rmse',predictionCol='prediction',labelCol='rating')\n",
    "crossval=CrossValidator(estimator=als,estimatorParamMaps=paramgrid,evaluator=evaluator,numFolds=5)\n",
    "crossmodel=crossval.fit(df_data_tarin)\n",
    "best_model=crossmodel.bestModel\n",
    "predictions=best_model.transform(df_data_test)\n",
    "rmse=evaluator.evaluate(predictions.filter(col('prediction')!='nan'))\n",
    "#model_path = f'file:///home/ali/Desktop/Movie Recommendation System/model/als_model_{datetime.date.today().strftime(\"%Y-%m-%d\")}_{rmse}'\n",
    "#os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "#best_model.save(model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hdfs://localhost:9000'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext._jsc.hadoopConfiguration().get(\"fs.defaultFS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendation=best_model.recommendForAllUsers(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9948:==============================================>      (87 + 8) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{1629, 4.907116}...|\n",
      "|     2|[{1629, 4.870393}...|\n",
      "|     3|[{1629, 3.8808732...|\n",
      "|     4|[{1629, 5.894905}...|\n",
      "|     5|[{1629, 4.076516}...|\n",
      "|     6|[{1629, 4.5347886...|\n",
      "|     7|[{1629, 5.192302}...|\n",
      "|     8|[{1629, 5.0268207...|\n",
      "|     9|[{1629, 5.2419786...|\n",
      "|    10|[{1629, 5.2083077...|\n",
      "|    11|[{1629, 4.627579}...|\n",
      "|    12|[{1599, 5.321684}...|\n",
      "|    13|[{1629, 4.313451}...|\n",
      "|    14|[{1629, 4.980708}...|\n",
      "|    15|[{1629, 4.0771594...|\n",
      "|    16|[{1629, 5.4262524...|\n",
      "|    17|[{1629, 4.1206236...|\n",
      "|    18|[{1629, 4.834357}...|\n",
      "|    19|[{1599, 4.1856008...|\n",
      "|    20|[{1500, 4.004752}...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recomendation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = spark.createDataFrame([(1,)], [\"userId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|     1|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_user=best_model.recommendForUserSubset(user_df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                             |\n",
      "+------+--------------------------------------------------------------------------------------------+\n",
      "|1     |[{1629, 4.907116}, {1599, 4.832293}, {1642, 4.791252}, {1467, 4.7408233}, {1398, 4.7407575}]|\n",
      "+------+--------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_user.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_user=rec_user.selectExpr('*',\"explode(recommendations) as rec\").drop('recommendations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------+---------+\n",
      "|userId|              rec|movieID|   rating|\n",
      "+------+-----------------+-------+---------+\n",
      "|     1| {1629, 4.907116}|   1629| 4.907116|\n",
      "|     1| {1599, 4.832293}|   1599| 4.832293|\n",
      "|     1| {1642, 4.791252}|   1642| 4.791252|\n",
      "|     1|{1467, 4.7408233}|   1467|4.7408233|\n",
      "|     1|{1398, 4.7407575}|   1398|4.7407575|\n",
      "+------+-----------------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = false)\n",
      " |-- rec: struct (nullable = true)\n",
      " |    |-- movieId: integer (nullable = true)\n",
      " |    |-- rating: float (nullable = true)\n",
      " |-- movieID: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_user.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_user = rec_user.withColumn(\"movieID\", col('rec.movieId')).withColumn(\"rating\", col('rec.rating')).drop('rec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+\n",
      "|userId|movieID|   rating|\n",
      "+------+-------+---------+\n",
      "|     1|   1629| 4.907116|\n",
      "|     1|   1599| 4.832293|\n",
      "|     1|   1642| 4.791252|\n",
      "|     1|   1467|4.7408233|\n",
      "|     1|   1398|4.7407575|\n",
      "+------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=1, movieID=1629, rating=4.907115936279297),\n",
       " Row(userId=1, movieID=1599, rating=4.8322930335998535),\n",
       " Row(userId=1, movieID=1642, rating=4.791252136230469),\n",
       " Row(userId=1, movieID=1467, rating=4.740823268890381),\n",
       " Row(userId=1, movieID=1398, rating=4.740757465362549)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_user.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_es=[row.asDict() for row in rec_user.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'userId': 1, 'movieID': 1629, 'rating': 4.907115936279297},\n",
       " {'userId': 1, 'movieID': 1599, 'rating': 4.8322930335998535},\n",
       " {'userId': 1, 'movieID': 1642, 'rating': 4.791252136230469},\n",
       " {'userId': 1, 'movieID': 1467, 'rating': 4.740823268890381},\n",
       " {'userId': 1, 'movieID': 1398, 'rating': 4.740757465362549}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"file:///model/als_model_2025-03-13_0.9794150959395667\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents: Nothing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"/home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\"\n",
    "print(\"Contents:\", os.listdir(path[7:]) if os.path.exists(path[7:]) else \"Nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o17298.load.\n: java.lang.NoSuchMethodException: org.apache.spark.ml.recommendation.ALSModel.<init>(java.lang.String)\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getConstructor(Class.java:1825)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:468)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m path = \u001b[33m\"\u001b[39m\u001b[33mfile:///home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best_model = \u001b[43mALS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/ml/util.py:369\u001b[39m, in \u001b[36mMLReadable.load\u001b[39m\u001b[34m(cls, path)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) -> RL:\n\u001b[32m    368\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/ml/util.py:318\u001b[39m, in \u001b[36mJavaMLReader.load\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mpath should be a string, got type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(path))\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m java_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._clazz, \u001b[33m\"\u001b[39m\u001b[33m_from_java\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis Java ML type cannot be loaded into Python currently: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m._clazz\n\u001b[32m    322\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o17298.load.\n: java.lang.NoSuchMethodException: org.apache.spark.ml.recommendation.ALSModel.<init>(java.lang.String)\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getConstructor(Class.java:1825)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:468)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "path = \"file:///home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\"\n",
    "best_model = ALS.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o17300.load.\n: org.apache.hadoop.ipc.RpcException: RPC response has invalid length\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1933)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m path = \u001b[33m\"\u001b[39m\u001b[33m/home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best_model = \u001b[43mALS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/ml/util.py:369\u001b[39m, in \u001b[36mMLReadable.load\u001b[39m\u001b[34m(cls, path)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) -> RL:\n\u001b[32m    368\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/ml/util.py:318\u001b[39m, in \u001b[36mJavaMLReader.load\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mpath should be a string, got type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(path))\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m java_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._clazz, \u001b[33m\"\u001b[39m\u001b[33m_from_java\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis Java ML type cannot be loaded into Python currently: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m._clazz\n\u001b[32m    322\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o17300.load.\n: org.apache.hadoop.ipc.RpcException: RPC response has invalid length\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1933)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\"\n",
    "best_model = ALS.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: An error occurred while calling o17302.load.\n",
      ": java.lang.NoSuchMethodException: org.apache.spark.ml.recommendation.ALSModel.<init>(java.lang.String)\n",
      "\tat java.lang.Class.getConstructor0(Class.java:3082)\n",
      "\tat java.lang.Class.getConstructor(Class.java:1825)\n",
      "\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:468)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "path = \"file:///home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\"\n",
    "try:\n",
    "    best_model = ALS.load(path)\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/13 14:52:33 WARN MemoryManager: Total allocation exceeds 95.00% (952,316,711 bytes) of heap memory\n",
      "Scaling row group sizes to 88.69% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(df_data)\n",
    "model.save(\"file:///home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o17386.load.\n: java.lang.NoSuchMethodException: org.apache.spark.ml.recommendation.ALSModel.<init>(java.lang.String)\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getConstructor(Class.java:1825)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:468)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrecommendation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALS\n\u001b[32m      2\u001b[39m path = \u001b[33m\"\u001b[39m\u001b[33mfile:///home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m best_model = \u001b[43mALS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaded successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/ml/util.py:369\u001b[39m, in \u001b[36mMLReadable.load\u001b[39m\u001b[34m(cls, path)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) -> RL:\n\u001b[32m    368\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/ml/util.py:318\u001b[39m, in \u001b[36mJavaMLReader.load\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mpath should be a string, got type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(path))\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m java_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._clazz, \u001b[33m\"\u001b[39m\u001b[33m_from_java\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis Java ML type cannot be loaded into Python currently: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m._clazz\n\u001b[32m    322\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Movie Recommendation System/venv/lib/python3.12/site-packages/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o17386.load.\n: java.lang.NoSuchMethodException: org.apache.spark.ml.recommendation.ALSModel.<init>(java.lang.String)\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getConstructor(Class.java:1825)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:468)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "path = \"file:///home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\"\n",
    "best_model = ALS.load(path)\n",
    "print(\"Loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "model = ALSModel.load(\"file:///home/ali/Desktop/Movie Recommendation System/model/als_model_2025-03-13_0.9794150959395667\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = spark.createDataFrame([(1,)], [\"userId\"])\n",
    "rec_user=model.recommendForUserSubset(user_df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{1449, 5.0420194...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_user.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
